{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyodbc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the environment\n",
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to MS SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the connection string to SQL Server\n",
    "trst_conn= \"Yes\"\n",
    "driver = \"ODBC Driver 17 for SQL Server\"\n",
    "server = \"localhost\"\n",
    "src_database = \"SharkAttacks\"     # Source DB\n",
    "# dest_database = \"Northwind2012STG\"    # Destination DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new connection to source DB (Trusted Connection -> Windows Authentication)\n",
    "trusted_conn_src = pyodbc.connect(f'DRIVER={driver};SERVER={server};DATABASE={src_database};TRUSTED_CONNECTION={trst_conn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from MS SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load table from source DB into a dataframe\n",
    "read_query='''\n",
    "SELECT *  FROM tblSharkAttacks\n",
    "'''\n",
    "df = pd.read_sql(read_query, trusted_conn_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary statistics\n",
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty rows/columns\n",
    "df.dropna(how=\"all\", axis=0, inplace=True) # Rows\n",
    "df.dropna(how=\"all\", axis=1, inplace=True) # Columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing spaces from 'object' (string) columns\n",
    "for col in df.select_dtypes(['object']).columns:\n",
    "    df[col] = df[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted characters (<, %, ?) from all rows\n",
    "df = df.replace(r'[<%?]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace a character with another character in a specific string column\n",
    "df['Date'] = df['Date'].str.replace('Reported ','')\n",
    "df['Time'] = df['Time'].str.replace('h',':')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns Fatal (Y/N) to Fatal and Investigator or Source to Source\n",
    "df = df.rename(columns={'Fatal (Y/N)':'Fatal', 'Investigator or Source':'Source'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "df.drop(['Year', 'pdf', 'href formula', 'href', 'Case Number1', 'Case Number2', 'original order', 'Source'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'percent_missing': percent_missing})\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with empty values in a column\n",
    "df.dropna(subset=['Case Number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty values for 'object' types with the most used value\n",
    "string_columns = df.select_dtypes(include=['object']).columns\n",
    "df[string_columns] = df[string_columns].fillna(df[string_columns].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace numerical nulls with mean\n",
    "df.fillna(df.mean(numeric_only=True).round(1), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "# Drop rows with empty values in a date column\n",
    "df.dropna(subset=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date parts into new columns\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Month Name'] = df['Date'].dt.strftime('%b')         # Extract Month date part in abbreviated format (e.g. August -> Aug)\n",
    "# df['Month Name'] = df['Date'].dt.month_name()\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['Weekday (Name)'] = df['Date'].dt.strftime('%a')     # Extract Weekday name date part in abbreviated format (e.g. Tuesday -> Tue)\n",
    "# df['Weekday (Name)'] = df['Date'].dt.day_name()\n",
    "df['Decade'] = df['Year'] - df['Year'] % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create buckets (bins) for Age\n",
    "# Define the bins and labels\n",
    "bins = [0, 12, 19, 35, 55, float('inf')]\n",
    "labels = ['0-11', '12-18', '19-34', '35-54', '55+']\n",
    "\n",
    "# Create a new column for age groups\n",
    "df['Age Group'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Location column and create a new column with the first part of the splitted column\n",
    "df['Location_1'] = df['Location'].str.split(',').str[0]\n",
    "\n",
    "# Split the Location column and create a new column with the second part of the splitted column\n",
    "df['County'] = df['Location'].str.split(',').str[1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the original column\n",
    "df.drop(['Location'], axis='columns', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the new column from the split, back to the name of the original column\n",
    "df = df.rename(columns={'Location_1':'Location'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save transformed data to flat file (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataframe to .CSV\n",
    "df.to_csv('sharkattacks_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
