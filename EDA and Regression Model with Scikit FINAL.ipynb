{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Business Understanding\n",
    "- Help in forecasting accounting transactions\n",
    "- Target column: Amount\n",
    "- Most likely, I'll use regression because of the continous nature of the target data\n",
    "- Data goes back for 3 years\n",
    "- Data quality is uncertain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the environment\n",
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file\n",
    "file_path = 'C:/Users/User/Downloads/Python/'\n",
    "file_name = 'regression.csv'\n",
    "\n",
    "df = pd.read_csv(file_path+file_name, header=0, delimiter=',', encoding='1253')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show last 5 rows of data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary statistics\n",
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty rows/columns\n",
    "df.dropna(how=\"all\", axis=0, inplace=True) # Rows\n",
    "df.dropna(how=\"all\", axis=1, inplace=True) # Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing spaces from 'object' (string) columns\n",
    "for col in df.select_dtypes(['object']).columns:\n",
    "    df[col] = df[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted characters (<, %, ?) from all rows\n",
    "df = df.replace(r'[<%?]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unique values for columns\n",
    "for col in df.columns:\n",
    "    print(col, len(df[col].unique()), df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for % missing values\n",
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'percent_missing': percent_missing})\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount range analysis by Account Type\n",
    "plt.figure(figsize=(20,6))\n",
    "sns.boxplot(x='Account Type', y='Amount', data=df).set_title('Account Type BoxPlot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore further the Liability Accont Type because it has the biggest dispersion\n",
    "plt.figure(figsize=(20,6))\n",
    "sns.boxplot(x='Account', y='Amount', data=df[df['Account Type']=='Liability']).set_title('Liability BoxPlot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same for Revenue\n",
    "plt.figure(figsize=(20,6))\n",
    "sns.boxplot(x='Account Description', y='Amount', data=df[df['Account Type']=='Revenue']).set_title('Revenue BoxPlot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Amount trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For trend examination, we need a create a Date column\n",
    "monthmap = {\n",
    "    'Jan':1,\n",
    "    'Feb':2,\n",
    "    'Mar':3,\n",
    "    'Apr':4,\n",
    "    'May':5,\n",
    "    'Jun':6,\n",
    "    'Jul':7,\n",
    "    'Aug':8,\n",
    "    'Sep':9,\n",
    "    'Oct':10,\n",
    "    'Nov':11,\n",
    "    'Dec':12,\n",
    "}\n",
    "\n",
    "df['Period'] = df['Month'].apply(lambda x: monthmap[x])\n",
    "df['Day'] = 1\n",
    "df['Date'] = df['Year'].astype(str) + '-' + df['Period'].astype(str) + '-' + df['Day'].astype(str)\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Revenue trends\n",
    "plt.figure(figsize=(20,6))\n",
    "sns.lineplot(x='Date', y='Amount', hue='Account Description', estimator=None, data=df[df['Account Type']=='Revenue']).set_title('Seasonal Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the messiness of the previous plot, I will concentrate on Product Sales\n",
    "plt.figure(figsize=(20,6))\n",
    "sns.lineplot(x='Date', y='Amount', hue='Account Description', estimator=None, data=df[df['Account Description']=='Product Sales']).set_title('Seasonal Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check another source of Revenue\n",
    "plt.figure(figsize=(20,6))\n",
    "sns.lineplot(x='Date', y='Amount', hue='Account Description', estimator=None, data=df[df['Account Description']=='Service Revenue']).set_title('Seasonal Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the relationship between different accounts (Unique rows in Account column).\n",
    "# In order to do that, we need to reshape our dataframe, so each Account will have each own column.\n",
    "pd.get_dummies(df['Account'])\n",
    "\n",
    "# Store the transformations to a dictionary\n",
    "corrdict = {}\n",
    "for key, row in df.join(pd.get_dummies(df['Account'])).iterrows():\n",
    "    corrdict[key] = {int(row['Account']):row['Amount']}\n",
    "\n",
    "# Transform the dictionary to dataframe\n",
    "corrdf = pd.DataFrame.from_dict(corrdict).T.fillna(0)\n",
    "\n",
    "# Calculate the correlations\n",
    "corrdf.corr()\n",
    "\n",
    "# Plot a heatmap\n",
    "plt.figure(figsize=(20,6))\n",
    "sns.heatmap(corrdf.corr(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on highly correlated Accounts\n",
    "df[df['Account']==3000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize each account seperately\n",
    "for account in df['Account'].unique():\n",
    "    plt.figure(figsize=(20,6))\n",
    "    sns.lineplot(x='Date', y='Amount', estimator=np.median, hue='Account Description', data=df[df['Account']==account]).set_title('{} by Month'.format(account))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out Inventory rows\n",
    "df = df[df['Account'] != 3000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Account'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert fields to correct data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Year, Account to 'object' data type\n",
    "df['Year'] = df['Year'].astype(str)\n",
    "df['Account'] = 'ACC' + df['Account'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns Period, Day, Date because the information is avaliable in Year, Month columns\n",
    "df.drop(['Period', 'Day', 'Date'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['Account'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['Account Description'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AccountVal'] = df['Account'] + df['Account Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns AccountVal, Account Description because the information is avaliable in Account\n",
    "df.drop(['Account Description', 'AccountVal'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform One-Hot Encoding to prepare the data for ML\n",
    "df_model = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the independent variables (X) and the dependent variable(y)\n",
    "X = df_model.drop('Amount', axis=1)\n",
    "y = df_model['Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the train and test partitions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use different Scikit regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=1234).fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor(random_state=1234).fit(X_train, y_train)\n",
    "gb_pred = gb.predict(X_test)\n",
    "\n",
    "# RidgeRegressor\n",
    "rdg = Ridge(random_state=1234).fit(X_train, y_train)\n",
    "rdg__pred = rdg.predict(X_test)\n",
    "\n",
    "# Lasso\n",
    "ls = Lasso(random_state=1234).fit(X_train, y_train)\n",
    "ls__pred = ls.predict(X_test)\n",
    "\n",
    "# ElasticNet\n",
    "enet = ElasticNet(random_state=1234).fit(X_train, y_train)\n",
    "enet__pred = enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our evaluation metrics to find the best model\n",
    "print(\"rf Accuracy: \"+ str(rf.score(X,y)))\n",
    "print(\"gb Accuracy: \"+ str(gb.score(X,y)))\n",
    "print(\"rdg Accuracy: \"+ str(rdg.score(X,y)))\n",
    "print(\"ls Accuracy: \"+ str(ls.score(X,y)))\n",
    "print(\"enet Accuracy: \"+ str(enet.score(X,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our best model is 'rf'. \n",
    "rf_pred_new = rf.predict(X)             # Predicts Amount for the whole dataset       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column in the original dataset with the predictions\n",
    "df['Amount_Pred'] = rf_pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
